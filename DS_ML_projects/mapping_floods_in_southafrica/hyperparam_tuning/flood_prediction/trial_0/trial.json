{"trial_id": "0", "hyperparameters": {"space": [{"class_name": "Int", "config": {"name": "filters", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 16, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "lstm_units", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 16, "sampling": "linear"}}], "values": {"filters": 128, "lstm_units": 112}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"c:\\Users\\Reinhard\\anaconda3\\envs\\Datascience\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\Reinhard\\anaconda3\\envs\\Datascience\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Reinhard\\anaconda3\\envs\\Datascience\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Reinhard\\anaconda3\\envs\\Datascience\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Reinhard\\anaconda3\\envs\\Datascience\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Reinhard\\anaconda3\\envs\\Datascience\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"c:\\Users\\Reinhard\\anaconda3\\envs\\Datascience\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n    except TypeError as e:\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nDetected at node StatefulPartitionedCall/gradient_tape/functional_1/bidirectional_1/backward_lstm_1/while/functional_1/bidirectional_1/backward_lstm_1/while_grad/body/_473/gradient_tape/functional_1/bidirectional_1/backward_lstm_1/while/gradients/functional_1/bidirectional_1/backward_lstm_1/while/lstm_cell_1/MatMul_grad/MatMul_1 defined at (most recent call last):\n<stack traces unavailable>\nOOM when allocating tensor with shape[129,448] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node StatefulPartitionedCall/gradient_tape/functional_1/bidirectional_1/backward_lstm_1/while/functional_1/bidirectional_1/backward_lstm_1/while_grad/body/_473/gradient_tape/functional_1/bidirectional_1/backward_lstm_1/while/gradients/functional_1/bidirectional_1/backward_lstm_1/while/lstm_cell_1/MatMul_grad/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_5952]\n"}