{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #type: ignore\n",
    "import pandas as pd #type: ignore\n",
    "\n",
    "import tensorflow as tf #type: ignore\n",
    "from tensorflow.keras import layers, Model #type: ignore\n",
    "from tensorflow.keras.layers import (Conv2D,MaxPooling1D, MaxPooling2D, Flatten,MaxPool1D, Dense, \n",
    "                                     LSTM, Bidirectional, Input, RepeatVector, \n",
    "                                     Concatenate, Dropout, GlobalAveragePooling2D, \n",
    "                                     Conv1D, BatchNormalization, Attention) #type: ignore\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold #type: ignore\n",
    "from sklearn.utils.class_weight import compute_class_weight #type: ignore\n",
    "from functools import partial #type: ignore\n",
    "import math #type: ignore\n",
    "from tqdm import tqdm #type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping #  type: ignore\n",
    "from imblearn.combine import SMOTETomek       # type: ignore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          event_id  precipitation  label  event_idx  event_t\n",
      "0  id_spictby0jfsb       0.000000      0          0        0\n",
      "1  id_spictby0jfsb       0.095438      0          0        1\n",
      "2  id_spictby0jfsb       1.949560      0          0        2\n",
      "3  id_spictby0jfsb       3.232160      0          0        3\n",
      "4  id_spictby0jfsb       0.000000      0          0        4\n",
      "          event_id  precipitation  event_idx  event_t\n",
      "0  id_j7b6sokflo4k        0.00000          0        0\n",
      "1  id_j7b6sokflo4k        3.01864          0        1\n",
      "2  id_j7b6sokflo4k        0.00000          0        2\n",
      "3  id_j7b6sokflo4k       16.61520          0        3\n",
      "4  id_j7b6sokflo4k        2.56706          0        4\n"
     ]
    }
   ],
   "source": [
    "train_df['event_id'] = train_df['event_id'].apply(lambda x: '_'.join(x.split('_')[0:2]))\n",
    "train_df['event_idx'] = train_df.groupby('event_id', sort=False).ngroup()\n",
    "test_df['event_id'] = test_df['event_id'].apply(lambda x: '_'.join(x.split('_')[0:2]))\n",
    "test_df['event_idx'] = test_df.groupby('event_id', sort=False).ngroup()\n",
    "\n",
    "train_df['event_t'] = train_df.groupby('event_id').cumcount()\n",
    "test_df['event_t'] = test_df.groupby('event_id').cumcount()\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for image preprocessing\n",
    "BAND_NAMES = ('B2', 'B3', 'B4', 'B8', 'B11', 'slope')\n",
    "H, W, NUM_CHANNELS = IMG_DIM = (128, 128, len(BAND_NAMES))\n",
    "_MAX_INT = np.iinfo(np.uint16).max\n",
    "\n",
    "def decode_slope(x):\n",
    "    return (x / _MAX_INT * (math.pi / 2.0)).astype(np.float32)\n",
    "\n",
    "def normalize(x, mean, std):\n",
    "    return (x - mean) / std\n",
    "\n",
    "rough_S2_normalize = partial(normalize, mean=1250, std=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(x):\n",
    "    return np.concatenate([\n",
    "        rough_S2_normalize(x[..., :-1].astype(np.float32)),\n",
    "        decode_slope(x[..., -1:]),\n",
    "    ], axis=-1, dtype=np.float32)\n",
    "\n",
    "def preprocess_precipitation(x):\n",
    "    return (x - np.mean(x)) / np.std(x)  # Standardize precipitation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load composite images\n",
    "with np.load('composite_images.npz') as data:\n",
    "    composite_images = {event_id: preprocess_image(data[event_id]) for event_id in data.keys()}\n",
    "\n",
    "# Placeholder for missing images\n",
    "def get_image(event_id):\n",
    "    if event_id in composite_images:\n",
    "        return composite_images[event_id]\n",
    "    return np.zeros((128, 128, 6), dtype=np.float32)  # Zero image for missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess time series and images\n",
    "def preprocess_data_and_images(data_df):\n",
    "    event_ids = data_df['event_id'].unique()\n",
    "    timeseries, labels, images = [], [], []\n",
    "\n",
    "    for event_id in tqdm(event_ids, desc='Processing data'):\n",
    "        event_data = data_df[data_df['event_id'] == event_id]\n",
    "        timeseries.append(preprocess_precipitation(event_data['precipitation'].values))\n",
    "        if 'label' in event_data.columns:\n",
    "            labels.append(event_data['label'].values)\n",
    "        images.append(get_image(event_id))\n",
    "    \n",
    "    return np.array(timeseries), np.array(labels) if labels else None, np.stack(images, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 674/674 [00:56<00:00, 11.95it/s]\n",
      "Processing data: 100%|██████████| 224/224 [00:04<00:00, 47.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_timeseries, train_labels, train_images = preprocess_data_and_images(train_df)\n",
    "test_timeseries, _, test_images = preprocess_data_and_images(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a deeper CNN for image feature extraction\n",
    "def build_image_encoder():\n",
    "    image_input = Input(shape=(128, 128, 6), name='image_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(image_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    encoded_image = Dense(128, activation='relu')(x)\n",
    "    return Model(image_input, encoded_image, name='Image_Encoder')\n",
    "\n",
    "# Define time series processing with CNN + LSTM\n",
    "def build_time_series_model():\n",
    "    precip_input = Input(shape=(730,), name='precip_input')\n",
    "    expanded_input = layers.Reshape((730, 1))(precip_input)\n",
    "    x = Conv1D(64, 3, activation='relu', padding='same')(expanded_input)\n",
    "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    attn = Attention()([x, x])  # Attention mechanism\n",
    "    x = Dense(64, activation='relu')(attn)\n",
    "    return Model(precip_input, x, name='TimeSeries_Model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge models\n",
    "image_encoder = build_image_encoder()\n",
    "time_series_model = build_time_series_model()\n",
    "\n",
    "def build_flood_prediction_model():\n",
    "    encoded_image = image_encoder.output\n",
    "    repeated_image_vector = RepeatVector(730)(encoded_image)\n",
    "    \n",
    "    encoded_timeseries = time_series_model.output\n",
    "    concatenated = Concatenate(axis=-1)([repeated_image_vector, encoded_timeseries])\n",
    "    x = Dense(64, activation='relu')(concatenated)\n",
    "    x = Dropout(0.2)(x)\n",
    "    day_probabilities = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[image_encoder.input, time_series_model.input], outputs=day_probabilities)\n",
    "    return model\n",
    "\n",
    "model = build_flood_prediction_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Focal Loss\n",
    "def focal_loss(alpha=0.25, gamma=2.):\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = 1e-8\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * tf.pow(1 - y_pred, gamma)\n",
    "        return tf.reduce_mean(weight * ce)\n",
    "    return loss\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=focal_loss(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels.argmax(axis=1)), y=train_labels.argmax(axis=1))\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 4.5842e-04 - loss: 7.5771e-10 - val_accuracy: 0.0014 - val_loss: 1.3459e-07\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 4.8492e-04 - loss: 3.4139e-09 - val_accuracy: 0.0014 - val_loss: 1.3051e-07\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 4.7318e-04 - loss: 8.7299e-10 - val_accuracy: 0.0014 - val_loss: 1.2823e-07\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 4.5334e-04 - loss: 9.9308e-10 - val_accuracy: 0.0014 - val_loss: 1.2921e-07\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 4.7379e-04 - loss: 7.2722e-10 - val_accuracy: 0.0014 - val_loss: 1.2784e-07\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 4.6740e-04 - loss: 9.2286e-10 - val_accuracy: 0.0014 - val_loss: 1.2545e-07\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 4.2579e-04 - loss: 8.9500e-10 - val_accuracy: 0.0014 - val_loss: 1.2348e-07\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 4.5815e-04 - loss: 1.7669e-09 - val_accuracy: 0.0014 - val_loss: 1.1865e-07\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 4.4313e-04 - loss: 6.0697e-10 - val_accuracy: 0.0014 - val_loss: 1.1618e-07\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 4.8145e-04 - loss: 1.8456e-09 - val_accuracy: 0.0014 - val_loss: 1.1360e-07\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 4.9692e-04 - loss: 6.6740e-10 - val_accuracy: 0.0014 - val_loss: 1.1258e-07\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 4.5350e-04 - loss: 3.2424e-09 - val_accuracy: 0.0014 - val_loss: 1.1114e-07\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 4.2630e-04 - loss: 6.2462e-10 - val_accuracy: 0.0014 - val_loss: 1.1054e-07\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 4.7271e-04 - loss: 6.2221e-10 - val_accuracy: 0.0014 - val_loss: 1.0949e-07\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 4.8334e-04 - loss: 1.1824e-09 - val_accuracy: 0.0014 - val_loss: 1.0727e-07\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 4.5589e-04 - loss: 9.1072e-10 - val_accuracy: 0.0014 - val_loss: 1.0474e-07\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 4.6260e-04 - loss: 1.0082e-09 - val_accuracy: 0.0014 - val_loss: 1.0100e-07\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 4.7915e-04 - loss: 4.9203e-10 - val_accuracy: 0.0014 - val_loss: 9.7676e-08\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 4.5484e-04 - loss: 3.9082e-10 - val_accuracy: 0.0014 - val_loss: 9.5740e-08\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 4.6819e-04 - loss: 1.2550e-09 - val_accuracy: 0.0014 - val_loss: 9.2646e-08\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 4.7980e-04 - loss: 1.6697e-09 - val_accuracy: 0.0014 - val_loss: 9.1362e-08\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 4.9137e-04 - loss: 1.9445e-09 - val_accuracy: 0.0014 - val_loss: 9.0983e-08\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 4.8337e-04 - loss: 2.0960e-09 - val_accuracy: 0.0014 - val_loss: 9.0922e-08\n",
      "Epoch 24/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 4.7404e-04 - loss: 7.8959e-10 - val_accuracy: 0.0014 - val_loss: 8.9978e-08\n",
      "Epoch 25/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 4.6321e-04 - loss: 6.1154e-10 - val_accuracy: 0.0014 - val_loss: 8.7724e-08\n",
      "Epoch 26/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 4.4268e-04 - loss: 6.6236e-10 - val_accuracy: 0.0014 - val_loss: 8.6523e-08\n",
      "Epoch 27/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 4.4488e-04 - loss: 4.7961e-10 - val_accuracy: 0.0014 - val_loss: 8.7116e-08\n",
      "Epoch 28/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 4.5137e-04 - loss: 1.3338e-09 - val_accuracy: 0.0014 - val_loss: 8.9132e-08\n",
      "Epoch 29/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 4.6166e-04 - loss: 1.2652e-08 - val_accuracy: 0.0014 - val_loss: 8.9243e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1faa2c9e1e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(\n",
    "    [train_images, train_timeseries], train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 662ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([test_images, test_timeseries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "sample_submission = pd.read_csv('SampleSubmission (2).csv')\n",
    "sample_submission['label'] = predictions.flatten()\n",
    "sample_submission.to_csv(\"submission_optimized2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_j7b6sokflo4k_X_0</td>\n",
       "      <td>0.981471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_j7b6sokflo4k_X_1</td>\n",
       "      <td>0.981485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_j7b6sokflo4k_X_2</td>\n",
       "      <td>0.981506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_j7b6sokflo4k_X_3</td>\n",
       "      <td>0.981526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_j7b6sokflo4k_X_4</td>\n",
       "      <td>0.981531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_id     label\n",
       "0  id_j7b6sokflo4k_X_0  0.981471\n",
       "1  id_j7b6sokflo4k_X_1  0.981485\n",
       "2  id_j7b6sokflo4k_X_2  0.981506\n",
       "3  id_j7b6sokflo4k_X_3  0.981526\n",
       "4  id_j7b6sokflo4k_X_4  0.981531"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
